# 数据结构与内存管理

## 目录

1. [核心数据结构](#1-核心数据结构)
2. [内存管理策略](#2-内存管理策略)  
3. [性能优化设计](#3-性能优化设计)
4. [多线程数据安全](#4-多线程数据安全)
5. [内存使用分析](#5-内存使用分析)

---

## 1. 核心数据结构

### 1.1 PathNode - 搜索节点

```cpp
struct PathNode {
    float fCost;                    // F值 = G + H (A*总评估成本)
    float gCost;                    // G值 (从起点的实际成本)
    int nodeNum;                    // 节点的一维索引
    ushort2 nodePos;                // 节点的二维坐标(x,z)
    bool exitOnly;                  // 仅允许离开的标志位
    
    // 构造函数
    PathNode() : fCost(0.0f), gCost(0.0f), nodeNum(0), 
                 nodePos(0, 0), exitOnly(false) {}
    
    // 比较操作符(用于优先队列)
    bool operator<(const PathNode& other) const {
        return fCost > other.fCost; // 最小堆
    }
};
```

**设计要点**:
- 使用`ushort2`节点坐标节省内存 (4字节 vs 8字节)
- `exitOnly`标志位优化工厂出口区域处理
- 总大小约20字节，缓存友好

### 1.2 PathNodeStateBuffer - 全局节点状态

```cpp
struct PathNodeStateBuffer {
    // 核心成本数组 (SoA布局)
    std::vector<float> fCost, gCost;              // A*成本值
    std::vector<uint8_t> nodeMask;                // 节点状态位掩码
    std::vector<uint8_t> nodeLinksObsoleteFlags; // 连接过时标志
    
    // 额外成本覆盖层
    std::vector<float> extraCosts[2];             // [0]:同步, [1]:异步
    const float* extraCostsOverlay[2];            // 成本覆盖指针
    
    // PathEstimator专用数据
    std::vector<std::vector<short2>> peNodeOffsets; // 节点偏移
    
    // === 核心接口 ===
    
    // 节点成本访问
    void SetNodeCosts(unsigned int idx, float f, float g) {
        fCost[idx] = f;
        gCost[idx] = g;
    }
    
    float GetNodeExtraCost(unsigned int x, unsigned int z, bool synced) const {
        const unsigned int index = z * mapDims.mapx + x;
        if (extraCostsOverlay[synced] != nullptr) {
            return extraCostsOverlay[synced][index];
        }
        return (index < extraCosts[synced].size()) ? extraCosts[synced][index] : 0.0f;
    }
    
    // 内存管理
    void Clear() {
        std::fill(fCost.begin(), fCost.end(), PATHCOST_INFINITY);
        std::fill(gCost.begin(), gCost.end(), PATHCOST_INFINITY);
        std::fill(nodeMask.begin(), nodeMask.end(), 0);
    }
    
    void Resize(unsigned int numBlocks, int2 dims) {
        fCost.resize(numBlocks, PATHCOST_INFINITY);
        gCost.resize(numBlocks, PATHCOST_INFINITY);
        nodeMask.resize(numBlocks, 0);
        nodeLinksObsoleteFlags.resize(numBlocks, 0);
        
        // 额外成本数组
        extraCosts[0].resize(dims.x * dims.y, 0.0f);
        extraCosts[1].resize(dims.x * dims.y, 0.0f);
    }
    
    // 内存占用计算
    uint32_t GetMemFootPrint() const {
        uint32_t memFootPrint = 0;
        
        memFootPrint += fCost.size() * sizeof(float);
        memFootPrint += gCost.size() * sizeof(float);
        memFootPrint += nodeMask.size() * sizeof(uint8_t);
        memFootPrint += nodeLinksObsoleteFlags.size() * sizeof(uint8_t);
        memFootPrint += (extraCosts[0].size() + extraCosts[1].size()) * sizeof(float);
        
        // PE节点偏移
        for (const auto& offsets : peNodeOffsets) {
            memFootPrint += offsets.size() * sizeof(short2);
        }
        
        return memFootPrint;
    }
};
```

**状态位掩码定义**:
```cpp
// 方向位 (0-7)
PATHOPT_LEFT = 1, PATHOPT_RIGHT = 2, PATHOPT_UP = 4, PATHOPT_DOWN = 8
PATHOPT_LEFT_UP = 16, PATHOPT_RIGHT_UP = 32, PATHOPT_LEFT_DOWN = 64, PATHOPT_RIGHT_DOWN = 128

// 状态位 (8-15)  
PATHOPT_OPEN = 256, PATHOPT_CLOSED = 512, PATHOPT_BLOCKED = 1024, PATHOPT_OBSOLETE = 2048
```

### 1.3 MultiPath - 分层路径容器

```cpp
struct MultiPath {
    // 三个分辨率层级的路径
    IPath::Path lowResPath;                     // 32x32块路径
    IPath::Path medResPath;                     // 16x16块路径
    IPath::Path maxResPath;                     // 1x1方格路径
    
    // 搜索元数据
    IPath::SearchResult searchResult;          // 搜索结果状态
    CCircularSearchConstraint peDef;            // 搜索约束定义
    
    // 请求上下文
    const MoveDef* moveDef;                     // 移动类型定义
    CSolidObject* caller;                       // 请求者单位
    unsigned int pathID;                        // 路径唯一ID
    
    // 路径属性
    bool finalGoal;                             // 是否为最终目标
    float searchTime;                           // 搜索耗时(毫秒)
    
    // === 工具方法 ===
    
    // 获取最详细的可用路径
    const IPath::Path& GetBestAvailablePath() const {
        if (!maxResPath.path.empty()) return maxResPath;
        if (!medResPath.path.empty()) return medResPath;
        return lowResPath;
    }
    
    // 计算总路径长度
    float CalculatePathLength() const {
        const IPath::Path& bestPath = GetBestAvailablePath();
        if (bestPath.path.empty()) return 0.0f;
        
        float length = 0.0f;
        for (size_t i = 1; i < bestPath.path.size(); ++i) {
            length += bestPath.path[i].distance(bestPath.path[i-1]);
        }
        return length;
    }
    
    // 清理路径数据
    void Clear() {
        lowResPath.path.clear();
        medResPath.path.clear();
        maxResPath.path.clear();
        searchResult = IPath::Error;
        caller = nullptr;
        pathID = 0;
    }
};
```

### 1.4 PathPriorityQueue - 优化的优先队列

```cpp
// 自定义向量容器避免std::vector开销
class PathVector {
public:
    PathNode* buf[MAX_SEARCHED_NODES];          // 固定大小缓冲区
    int bufPos = 0;                             // 当前位置
    
    void clear() { bufPos = 0; }
    void push_back(PathNode* node) { buf[bufPos++] = node; }
    PathNode*& operator[](int idx) { return buf[idx]; }
    int size() const { return bufPos; }
};

// 高性能优先队列
class PathPriorityQueue : public std::priority_queue<PathNode*, PathVector, lessCost> {
public:
    void Clear() { 
        c.clear(); // 直接清空底层容器
    }
    
    unsigned int Size() const { return c.size(); }
    
    // 批量操作优化
    template<typename Iterator>
    void push_range(Iterator first, Iterator last) {
        for (auto it = first; it != last; ++it) {
            push(*it);
        }
    }
};

// 稳定排序比较器
struct lessCost {
    bool operator()(const PathNode* lhs, const PathNode* rhs) const {
        // 三级比较确保确定性
        // 1. F成本优先 2. G成本倒序(H成本正序) 3. 节点编号
        if (lhs->fCost != rhs->fCost) return lhs->fCost > rhs->fCost;
        if (lhs->gCost != rhs->gCost) return lhs->gCost < rhs->gCost;
        return lhs->nodeNum > rhs->nodeNum;
    }
};
```

---

## 2. 内存管理策略

### 2.1 对象池模式

```cpp
// 节点内存池 - 避免频繁分配
class PathNodeBuffer {
private:
    PathNode buffer[MAX_SEARCHED_NODES];        // 预分配缓冲区
    unsigned int idx = 0;                       // 当前分配位置
    
public:
    PathNode* GetNode(unsigned int i) {
        assert(i < MAX_SEARCHED_NODES);
        return &buffer[i];
    }
    
    void Clear() {
        // 只重置已使用的节点
        for (unsigned int i = 0; i < idx; ++i) {
            buffer[i] = PathNode{};
        }
        idx = 0;
    }
    
    void SetSize(unsigned int size) { 
        assert(size <= MAX_SEARCHED_NODES);
        idx = size; 
    }
    
    unsigned int GetSize() const { return idx; }
    
    // 批量分配接口
    PathNode* AllocateNodes(unsigned int count) {
        if (idx + count > MAX_SEARCHED_NODES) return nullptr;
        
        PathNode* result = &buffer[idx];
        idx += count;
        return result;
    }
};
```

### 2.2 统一内存分配

```cpp
// HAPFS系统统一内存管理
void CPathManager::AllocateMemory() {
    // === 计算内存需求 ===
    
    const size_t pathFinderSize = sizeof(CPathFinder);
    const size_t pathEstimatorSize = sizeof(CPathEstimator);
    const size_t pathingStateSize = sizeof(PathingState);
    
    // 每线程实例数量
    const size_t pathFinderMem = pathFinderGroups * pathFinderSize;
    const size_t pathEstimatorMem = pathFinderGroups * pathEstimatorSize * 2; // 2个分辨率
    const size_t pathingStateMem = pathingStateSize * 2; // 低分辨率 + 中分辨率
    
    // 对齐内存分配
    const size_t totalMem = AlignTo64Bytes(pathFinderMem + pathEstimatorMem + pathingStateMem);
    
    // === 单次大块分配 ===
    void* baseMemory = std::aligned_alloc(64, totalMem); // 64字节对齐
    if (!baseMemory) {
        throw std::bad_alloc();
    }
    
    std::memset(baseMemory, 0, totalMem);
    
    // === 手动内存布局 ===
    char* memPtr = static_cast<char*>(baseMemory);
    
    // PathFinder实例数组
    maxResPFs = reinterpret_cast<CPathFinder*>(memPtr);
    memPtr += pathFinderMem;
    
    // PathEstimator实例数组 
    lowResPEs = reinterpret_cast<CPathEstimator*>(memPtr);
    memPtr += pathFinderGroups * pathEstimatorSize;
    
    medResPEs = reinterpret_cast<CPathEstimator*>(memPtr);
    memPtr += pathFinderGroups * pathEstimatorSize;
    
    // PathingState实例
    pathingStates = reinterpret_cast<PathingState*>(memPtr);
    
    // === Placement New 就地构造 ===
    for (int i = 0; i < pathFinderGroups; ++i) {
        new (&maxResPFs[i]) CPathFinder(SQUARE_SIZE);
        new (&lowResPEs[i]) CPathEstimator(&pathingStates[LOWRES_PE], 
                                          LOWRES_PE_BLOCKSIZE, "pe", maxResPFs);
        new (&medResPEs[i]) CPathEstimator(&pathingStates[MEDRES_PE], 
                                          MEDRES_PE_BLOCKSIZE, "pe", maxResPFs);
    }
    
    new (&pathingStates[LOWRES_PE]) PathingState();
    new (&pathingStates[MEDRES_PE]) PathingState();
    
    LOG("HAPFS allocated %.2f MB of memory", totalMem / (1024.0f * 1024.0f));
}
```

### 2.3 RAII和智能指针

```cpp
// PathNodeStateBuffer的移动语义支持
struct PathNodeStateBuffer {
    // 禁止拷贝构造和拷贝赋值
    PathNodeStateBuffer(const PathNodeStateBuffer&) = delete;
    PathNodeStateBuffer& operator=(const PathNodeStateBuffer&) = delete;
    
    // 支持移动语义
    PathNodeStateBuffer(PathNodeStateBuffer&& other) noexcept {
        *this = std::move(other);
    }
    
    PathNodeStateBuffer& operator=(PathNodeStateBuffer&& other) noexcept {
        if (this != &other) {
            // 移动所有成员
            fCost = std::move(other.fCost);
            gCost = std::move(other.gCost);  
            nodeMask = std::move(other.nodeMask);
            nodeLinksObsoleteFlags = std::move(other.nodeLinksObsoleteFlags);
            
            for (int i = 0; i < 2; ++i) {
                extraCosts[i] = std::move(other.extraCosts[i]);
                extraCostsOverlay[i] = other.extraCostsOverlay[i];
            }
            
            peNodeOffsets = std::move(other.peNodeOffsets);
            
            // 重置源对象
            other.Clear();
        }
        return *this;
    }
    
    ~PathNodeStateBuffer() = default;
};

// 智能指针管理PathCache
class CPathCache {
private:
    using CachePtr = std::unique_ptr<CacheItem>;
    spring::unordered_map<uint64_t, CachePtr> cachedPaths;
    
public:
    void AddPath(std::unique_ptr<CacheItem> item) {
        uint64_t hash = CalculateHash(*item);
        cachedPaths[hash] = std::move(item);
    }
    
    std::unique_ptr<CacheItem> RemovePath(uint64_t hash) {
        auto it = cachedPaths.find(hash);
        if (it != cachedPaths.end()) {
            auto result = std::move(it->second);
            cachedPaths.erase(it);
            return result;
        }
        return nullptr;
    }
};
```

---

## 3. 性能优化设计

### 3.1 缓存友好的数据布局

```cpp
// SoA (Structure of Arrays) 布局优化
class OptimizedNodeStorage {
private:
    // 热数据 - 频繁访问的成本值
    struct HotData {
        std::vector<float> fCost;            // 连续的F成本数组
        std::vector<float> gCost;            // 连续的G成本数组
        std::vector<uint16_t> nodePos;       // 压缩的位置数据
    } hotData;
    
    // 冷数据 - 偶尔访问的状态信息
    struct ColdData {
        std::vector<uint8_t> nodeMask;       // 状态掩码
        std::vector<uint8_t> linkFlags;      // 连接标志
        std::vector<float> extraCosts;       // 额外成本
    } coldData;
    
public:
    // 批量成本访问 - 利用缓存局部性
    void GetCostRange(unsigned int start, unsigned int count, float* fCosts, float* gCosts) const {
        std::memcpy(fCosts, &hotData.fCost[start], count * sizeof(float));
        std::memcpy(gCosts, &hotData.gCost[start], count * sizeof(float));
    }
    
    // 预取优化
    void PrefetchCostData(unsigned int nodeIndex) const {
        __builtin_prefetch(&hotData.fCost[nodeIndex], 0, 3); // 预取到L3缓存
        __builtin_prefetch(&hotData.gCost[nodeIndex], 0, 3);
    }
};
```

### 3.2 内存对齐优化

```cpp
// 关键数据结构的内存对齐
struct alignas(64) AlignedPathNode {       // 64字节对齐(缓存行大小)
    float fCost;                           // 4字节
    float gCost;                           // 4字节  
    int nodeNum;                           // 4字节
    ushort2 nodePos;                       // 4字节
    bool exitOnly;                         // 1字节
    char padding[47];                      // 填充到64字节
    
    static_assert(sizeof(AlignedPathNode) == 64);
};

// SIMD优化的批量操作
class SIMDPathOperations {
public:
    // 使用AVX2指令集批量计算F成本
    void CalculateFCostsBatch(const float* gCosts, const float* hCosts, 
                             float* fCosts, size_t count) {
        constexpr size_t simdWidth = 8; // AVX2处理8个float
        const size_t simdCount = count & ~(simdWidth - 1);
        
        for (size_t i = 0; i < simdCount; i += simdWidth) {
            __m256 g = _mm256_load_ps(&gCosts[i]);
            __m256 h = _mm256_load_ps(&hCosts[i]);
            __m256 f = _mm256_add_ps(g, h);
            _mm256_store_ps(&fCosts[i], f);
        }
        
        // 处理剩余元素
        for (size_t i = simdCount; i < count; ++i) {
            fCosts[i] = gCosts[i] + hCosts[i];
        }
    }
};
```

### 3.3 内存池分配器

```cpp
// 高性能内存池分配器
template<size_t BlockSize, size_t BlockCount>
class FixedSizeMemoryPool {
private:
    alignas(64) char memory[BlockSize * BlockCount];   // 预分配内存
    std::bitset<BlockCount> allocatedBlocks;           // 分配位图
    size_t nextFreeBlock = 0;                          // 下一个空闲块提示
    
public:
    void* Allocate() {
        // 从提示位置开始查找空闲块
        for (size_t i = nextFreeBlock; i < BlockCount; ++i) {
            if (!allocatedBlocks[i]) {
                allocatedBlocks[i] = true;
                nextFreeBlock = i + 1;
                return &memory[i * BlockSize];
            }
        }
        
        // 回绕查找
        for (size_t i = 0; i < nextFreeBlock; ++i) {
            if (!allocatedBlocks[i]) {
                allocatedBlocks[i] = true;
                nextFreeBlock = i + 1;
                return &memory[i * BlockSize];
            }
        }
        
        return nullptr; // 池已满
    }
    
    void Deallocate(void* ptr) {
        if (!ptr) return;
        
        const size_t blockIndex = (static_cast<char*>(ptr) - memory) / BlockSize;
        if (blockIndex < BlockCount) {
            allocatedBlocks[blockIndex] = false;
            nextFreeBlock = std::min(nextFreeBlock, blockIndex);
        }
    }
    
    float GetUtilization() const {
        return float(allocatedBlocks.count()) / BlockCount;
    }
};

// 特化的PathNode池
using PathNodePool = FixedSizeMemoryPool<sizeof(PathNode), MAX_SEARCHED_NODES>;
```

---

## 4. 多线程数据安全

### 4.1 无锁数据结构

```cpp
// 无锁原子计数器
class AtomicCounter {
private:
    std::atomic<std::int64_t> counter{0};
    
public:
    std::int64_t GetNext() {
        return counter.fetch_add(1, std::memory_order_relaxed);
    }
    
    std::int64_t GetCurrent() const {
        return counter.load(std::memory_order_acquire);
    }
    
    void Reset() {
        counter.store(0, std::memory_order_release);
    }
};

// 线程局部存储优化
class ThreadLocalPathData {
private:
    static thread_local PathNodeBuffer nodeBuffer;
    static thread_local std::vector<unsigned int> dirtyBlocks;
    static thread_local PathPriorityQueue openBlocks;
    
public:
    static PathNodeBuffer& GetNodeBuffer() { return nodeBuffer; }
    static std::vector<unsigned int>& GetDirtyBlocks() { return dirtyBlocks; }
    static PathPriorityQueue& GetOpenBlocks() { return openBlocks; }
    
    static void ClearAll() {
        nodeBuffer.Clear();
        dirtyBlocks.clear();
        openBlocks.Clear();
    }
};
```

### 4.2 读写锁实现

```cpp
// 高性能读写锁
class SharedMutex {
private:
    mutable std::atomic<int> readers{0};           // 读者数量
    mutable std::atomic<bool> writer{false};       // 写者标志
    mutable std::mutex writerMutex;                // 写者互斥锁
    
public:
    // 共享锁定 (读)
    void lock_shared() const {
        while (true) {
            // 等待写者完成
            while (writer.load(std::memory_order_acquire)) {
                std::this_thread::yield();
            }
            
            // 增加读者计数
            readers.fetch_add(1, std::memory_order_acq_rel);
            
            // 双重检查，确保没有写者介入
            if (!writer.load(std::memory_order_acquire)) {
                break; // 成功获取共享锁
            }
            
            // 写者介入，撤销读者计数
            readers.fetch_sub(1, std::memory_order_acq_rel);
        }
    }
    
    void unlock_shared() const {
        readers.fetch_sub(1, std::memory_order_acq_rel);
    }
    
    // 独占锁定 (写)
    void lock() const {
        std::lock_guard<std::mutex> lock(writerMutex);
        writer.store(true, std::memory_order_release);
        
        // 等待所有读者完成
        while (readers.load(std::memory_order_acquire) > 0) {
            std::this_thread::yield();
        }
    }
    
    void unlock() const {
        writer.store(false, std::memory_order_release);
    }
};

// 线程安全的路径映射表
class ThreadSafePathMap {
private:
    std::map<unsigned int, MultiPath> pathMap;
    mutable SharedMutex mapMutex;
    
public:
    // 读操作
    MultiPath GetPath(unsigned int pathID) const {
        std::shared_lock<SharedMutex> lock(mapMutex);
        auto it = pathMap.find(pathID);
        return (it != pathMap.end()) ? it->second : MultiPath{};
    }
    
    // 写操作
    void SetPath(unsigned int pathID, const MultiPath& path) {
        std::unique_lock<SharedMutex> lock(mapMutex);
        pathMap[pathID] = path;
    }
    
    void RemovePath(unsigned int pathID) {
        std::unique_lock<SharedMutex> lock(mapMutex);
        pathMap.erase(pathID);
    }
};
```

### 4.3 内存序保证

```cpp
// 内存序优化的状态更新
class AtomicPathState {
private:
    std::atomic<uint32_t> state{0};
    
    // 状态位定义
    static constexpr uint32_t OPEN_BIT = 1;
    static constexpr uint32_t CLOSED_BIT = 2;
    static constexpr uint32_t DIRTY_BIT = 4;
    
public:
    bool IsOpen() const {
        return state.load(std::memory_order_acquire) & OPEN_BIT;
    }
    
    bool IsClosed() const {
        return state.load(std::memory_order_acquire) & CLOSED_BIT;
    }
    
    void SetOpen() {
        state.fetch_or(OPEN_BIT, std::memory_order_acq_rel);
    }
    
    void SetClosed() {
        uint32_t expected = state.load(std::memory_order_relaxed);
        uint32_t desired;
        
        do {
            desired = (expected & ~OPEN_BIT) | CLOSED_BIT;
        } while (!state.compare_exchange_weak(expected, desired, 
                                              std::memory_order_acq_rel,
                                              std::memory_order_relaxed));
    }
    
    void Clear() {
        state.store(0, std::memory_order_release);
    }
};
```

---

## 5. 内存使用分析

### 5.1 内存占用统计

```cpp
struct MemoryUsageStats {
    // 核心数据结构
    size_t pathNodeBuffers;              // 路径节点缓冲区
    size_t pathNodeStates;               // 节点状态缓冲区
    size_t pathCache;                    // 路径缓存
    size_t pathMaps;                     // 路径映射表
    
    // 辅助数据结构
    size_t heatMapData;                  // 热力图数据
    size_t flowMapData;                  // 流场数据
    size_t precomputedCosts;             // 预计算成本
    
    // 临时数据
    size_t temporaryBuffers;             // 临时缓冲区
    size_t dirtyBlockLists;              // 脏块列表
    
    size_t GetTotalUsage() const {
        return pathNodeBuffers + pathNodeStates + pathCache + pathMaps +
               heatMapData + flowMapData + precomputedCosts +
               temporaryBuffers + dirtyBlockLists;
    }
    
    void LogUsage() const {
        LOG("HAPFS Memory Usage Analysis:");
        LOG("  Path Node Buffers: %.2f MB", pathNodeBuffers / (1024.0f * 1024.0f));
        LOG("  Path Node States:  %.2f MB", pathNodeStates / (1024.0f * 1024.0f));
        LOG("  Path Cache:        %.2f MB", pathCache / (1024.0f * 1024.0f));
        LOG("  Path Maps:         %.2f MB", pathMaps / (1024.0f * 1024.0f));
        LOG("  Heat Map:          %.2f MB", heatMapData / (1024.0f * 1024.0f));
        LOG("  Flow Map:          %.2f MB", flowMapData / (1024.0f * 1024.0f));
        LOG("  Precomputed Costs: %.2f MB", precomputedCosts / (1024.0f * 1024.0f));
        LOG("  Temporary Data:    %.2f MB", (temporaryBuffers + dirtyBlockLists) / (1024.0f * 1024.0f));
        LOG("  Total Usage:       %.2f MB", GetTotalUsage() / (1024.0f * 1024.0f));
    }
};
```

### 5.2 内存使用监控

```cpp
class MemoryMonitor {
private:
    MemoryUsageStats currentStats;
    MemoryUsageStats peakStats;
    std::chrono::steady_clock::time_point lastUpdate;
    
public:
    void Update() {
        auto now = std::chrono::steady_clock::now();
        if (std::chrono::duration_cast<std::chrono::seconds>(now - lastUpdate).count() < 10) {
            return; // 每10秒更新一次
        }
        
        // 收集内存使用统计
        currentStats = CollectMemoryStats();
        
        // 更新峰值
        peakStats.pathNodeBuffers = std::max(peakStats.pathNodeBuffers, currentStats.pathNodeBuffers);
        peakStats.pathNodeStates = std::max(peakStats.pathNodeStates, currentStats.pathNodeStates);
        // ... 其他峰值更新
        
        // 内存使用预警
        const size_t totalUsage = currentStats.GetTotalUsage();
        const size_t memoryLimit = 1024 * 1024 * 1024; // 1GB限制
        
        if (totalUsage > memoryLimit * 0.9f) {
            LOG_L(L_WARNING, "HAPFS memory usage high: %.1f%% of limit", 
                  100.0f * totalUsage / memoryLimit);
            TriggerMemoryOptimization();
        }
        
        lastUpdate = now;
    }
    
private:
    MemoryUsageStats CollectMemoryStats() {
        MemoryUsageStats stats{};
        
        // 收集各组件的内存使用情况
        stats.pathNodeBuffers = pathManager->GetNodeBufferMemory();
        stats.pathNodeStates = pathManager->GetStateBufferMemory();
        stats.pathCache = pathManager->GetCacheMemory();
        // ... 其他统计收集
        
        return stats;
    }
    
    void TriggerMemoryOptimization() {
        // 触发内存优化策略
        pathManager->ReduceCacheSize();
        pathManager->CompactMemory();
        pathManager->ClearUnusedBuffers();
    }
};
```

### 5.3 地图大小vs内存使用

```cpp
// 不同地图大小的内存需求分析
struct MapSizeMemoryAnalysis {
    int mapWidth, mapHeight;
    size_t estimatedMemoryMB;
    
    static MapSizeMemoryAnalysis AnalyzeMapSize(int width, int height) {
        MapSizeMemoryAnalysis analysis;
        analysis.mapWidth = width;
        analysis.mapHeight = height;
        
        const size_t mapSquares = width * height;
        
        // 节点状态缓冲区 (每方格16字节)
        const size_t stateBufferSize = mapSquares * 16;
        
        // 预计算成本 (每块每移动类型每方向4字节)
        const size_t blocksCount = (width / 16) * (height / 16); // 16x16块
        const size_t precomputedSize = blocksCount * 8 * 8 * 4; // 8方向 * 8移动类型 * 4字节
        
        // 热力图和流场 (简化估算)
        const size_t heatMapSize = mapSquares * 4; // 每方格4字节
        const size_t flowMapSize = (mapSquares / 1024) * 16; // 32x32降采样，每格16字节
        
        // 路径缓存 (动态，估算为固定开销)
        const size_t cacheSize = 64 * 1024 * 1024; // 64MB
        
        // 临时缓冲区
        const size_t tempBufferSize = MAX_SEARCHED_NODES * sizeof(PathNode) * 4; // 4个线程
        
        analysis.estimatedMemoryMB = (stateBufferSize + precomputedSize + 
                                     heatMapSize + flowMapSize + 
                                     cacheSize + tempBufferSize) / (1024 * 1024);
        
        return analysis;
    }
};

// 常见地图大小的内存需求表
void PrintMemoryRequirements() {
    const int mapSizes[][2] = {
        {512, 512}, {1024, 1024}, {2048, 2048}, {4096, 4096}
    };
    
    LOG("HAPFS Memory Requirements by Map Size:");
    for (const auto& size : mapSizes) {
        auto analysis = MapSizeMemoryAnalysis::AnalyzeMapSize(size[0], size[1]);
        LOG("  %dx%d: ~%zu MB", size[0], size[1], analysis.estimatedMemoryMB);
    }
}
```

HAPFS系统的数据结构和内存管理体现了现代C++的最佳实践，通过精心设计的内存布局、对象池管理和多线程安全机制，在保证功能完整性的同时实现了出色的性能表现。这些设计为大规模RTS游戏提供了强大而高效的寻路基础设施。